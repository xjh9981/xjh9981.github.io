---
---

@string{aps = {American Physical Society,}}


@INPROCEEDINGS{doublecheck_percom,
  author={Dong, Xuefu and Han, Zengyi and Nishiyama, Yuuki and Sezaki, Kaoru},
  booktitle={2022 IEEE International Conference on Pervasive Computing and Communications Workshops and other Affiliated Events (PerCom Workshops)}, 
  title={DoubleCheck: Detecting Single-Hand Cycling with Inertial Measurement Unit of Smartphone}, 
  year={2022},
  volume={},
  number={},
  pages={50-53},
  keywords={Pervasive computing;Measurement units;Conferences;Computational modeling;Transportation;Scattering;Road safety;Human Activity Recognition;Mobile Sensing;Road Transportation},
  doi={10.1109/PerComWorkshops53856.2022.9767429},
  pdf={https://ieeexplore.ieee.org/document/9767429},
  abstract={Riding bikes with only one hand on the handlebar can severely undermine the steering capability of riders and risk road safety. In this study, we propose a first detection framework for monitoring single-hand cycling on bicycle travel, called DoubleCheck. It is based on the premise that riders adapt their body movement during single-hand cycling, which is distinguishable to the sensors even amid noise from the exasperate road surface. The system can detect handlebar-holding under different road conditions using motion signals from a built-in inertial measurement unit (IMU) in a handlebar-mounted smartphone. We implemented the system and invited 10 participants for our evaluation experiment. Our results show that DoubleCheck achieved an F1-score of 0.94 for hand detection, proving its efficacy for real-life implementation to improve road safety.},
  preview = {doublecheck_teaser.png},
  selected = {true}}


@INPROCEEDINGS{doublecheck_smc,
  author={Dong, Xuefu and Han, Zengyi and Nishiyama, Yuuki and Sezaki, Kaoru},
  booktitle={2022 IEEE International Conference on Systems, Man, and Cybernetics (SMC)}, 
  title={DoubleCheck: Single-Handed Cycling Detection with a Smartphone}, 
  year={2022},
  volume={},
  number={},
  pages={268-274},
  keywords={Roads;System performance;Transportation;Scattering;Bicycles;Software;Real-time systems;Cyclist Safety;Human Activity Recognition;Mobile Sensing},
  doi={10.1109/SMC53654.2022.9945380},
  pdf={https://ieeexplore.ieee.org/document/9945380}
}

@INPROCEEDINGS{headmon,
  author={Han, Zengyi and Xu, Liqiang and Dong, Xuefu and Nishiyama, Yuuki and Sezaki, Kaoru},
  booktitle={2023 IEEE International Conference on Pervasive Computing and Communications (PerCom)}, 
  title={HeadMon: Head Dynamics Enabled Riding Maneuver Prediction}, 
  year={2023},
  volume={},
  number={},
  pages={22-31},
  keywords={Pervasive computing;Measurement units;Head;Urban areas;Deep architecture;Prototypes;Inertial navigation;Human Activity Prediction;Head Movement;Mobile Computing},
  doi={10.1109/PERCOM56429.2023.10099215},
  pdf = {https://ieeexplore.ieee.org/document/10099215},
  abstract = {Although micro-mobility brings convenience to modern cities, they also cause various social problems, such as traffic accidents, casualties, and substantial economic losses. Wearing protective equipment has become the primary recommendation for safe riding. However, passive protection cannot prevent the occurrence of accidents. Thus, timely predicting the rider's maneuver is essential for active protection and providing more time to avoid potential accidents from happening. Through the qualitative study, we argue that we can use the rider's head dynamic as an information source to predict the rider's following maneuvers. We accordingly present HeadMon, a riding maneuver prediction system for safe riding. HeadMon utilizes the head dynamics of a rider by installing an inertial measurement unit on the helmet. It uses the extracted head dynamics features as the input of the deep learning architecture to achieve prediction. We implemented the HeadMon prototype on Android smartphone as a proof of concept. Through comprehensive experiments with 20 participants, the result demonstrates the excellent performance of HeadMon: not only could it achieve an overall precision of at least 85\% for maneuver prediction under a 4s prediction time gap, but it also could keep a high accuracy under a low sampling rate. The low-cost feature of HeadMon allows it to be readily deployable and towards more safety riding.},
  preview = {headmon_teaser.png},
  note = {Acceptance Rate 17\%}}

@INPROCEEDINGS{headsense,
  author={Han, Zengyi and Dong, Xuefu and Nishiyama, Yuuki and Sezaki, Kaoru},
  booktitle={2023 IEEE 24th International Symposium on a World of Wireless, Mobile and Multimedia Networks (WoWMoM)}, 
  title={HeadSense: Visual Search Monitoring and Distracted Behavior Detection for Bicycle Riders}, 
  year={2023},
  volume={},
  number={},
  pages={281-289},
  keywords={Wireless communication;Visualization;Wireless sensor networks;Machine learning algorithms;Bicycles;Magnetic heads;Behavioral sciences;Human Activity Recognition;Mobile Sensing;Head Movement Detection},
  doi={10.1109/WoWMoM57956.2023.00043},
  pdf={https://ieeexplore.ieee.org/abstract/document/10195692},
  preview = {headsense_teaser.png},
  selected = {true},
  abstract = {Distracted riding behavior is one of the main causes of bicycle-related traffic accidents, resulting in a large number of casualties and economic losses every year. There is an urgent need to address this problem by accurately detecting distracted riding behaviors. Inspired by the observation that distracted riding behaviors induce unique head motion features that respond to the rider’s attention, we present the HeadSense, a helmet-based system that not only monitors the visual search episode of the rider but also detects distracted riding behaviors. Specifically, HeadSense leverages the inertial motion unit (IMU) to recognize distracted behaviors such as using smartphones, attracting to the roadside element, and abreast riding. We designed, implemented, and evaluated HeadSense through extensive experiments. We conducted experiments with 19 participants inside the university’s campus. The experimental results show that HeadSense can achieve an overall accuracy of 86.14\% while monitoring visual search episodes. Moreover, HeadSense can detect the occurrence of distracted riding behaviors with an average precision of up to 85.04\%.},
  note = {Acceptance Rate 28.2\%}
}

@inproceedings{rehearsse,
author = {Dong, Xuefu and Chen, Yifei and Nishiyama, Yuuki and Sezaki, Kaoru and Wang, Yuntao and Christofferson, Ken and Mariakakis, Alex},
title = {ReHEarSSE: Recognizing Hidden-in-the-Ear Silently Spelled Expressions},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642095},
doi = {10.1145/3613904.3642095},
abstract = {Silent speech interaction (SSI) allows users to discreetly input text without using their hands. Existing wearable SSI systems typically require custom devices and are limited to a small lexicon, limiting their utility to a small set of command words. This work proposes ReHEarSSE, an earbud-based ultrasonic SSI system capable of generalizing to words that do not appear in its training dataset, providing support for nearly an entire dictionary’s worth of words. As a user silently spells words, ReHEarSSE uses autoregressive features to identify subtle changes in ear canal shape. ReHEarSSE infers words using a deep learning model trained to optimize connectionist temporal classification (CTC) loss with an intermediate embedding that accounts for different letters and transitions between them. We find that ReHEarSSE recognizes 100 unseen words with an accuracy of 89.3\%.},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {321},
numpages = {16},
keywords = {acoustic sensing, autoregressive model, earable computing, silent speech interface, text entry},
location = {<conf-loc>, <city>Honolulu</city>, <state>HI</state>, <country>USA</country>, </conf-loc>},
series = {CHI '24},
video = {https://www.youtube.com/embed/WenCEJnNx0M},
preview = {re_canal.png},
pdf={https://dl.acm.org/doi/pdf/10.1145/3613904.3642095},
note = {Acceptance Rate 26.3\%},
selected = {true}
}

@inproceedings{rideguard,
  title={RideGuard: Micro-Mobility Steering Maneuver Prediction with Smartphones},
  author={Han, Zengyi and Dong, Xuefu and Xu, Liqiang and Zhu, Zhen and Wang, En and Nishiyama, Yuuki and Sezaki, Kaoru},
  booktitle={2024 IEEE 44th International Conference on Distributed Computing Systems (ICDCS)},
  year={2024},
  organization={IEEE},
  preview = {rideguard_teaser.png},
  selected = {true},
  note = {Acceptance Rate 21.9\%}
}
}
